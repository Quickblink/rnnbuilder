{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append('library/src')\n",
    "import rnnbuilder as rb\n",
    "from rnnbuilder import custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from rnnbuilder.nn import ReLU, Conv2d, Linear, Tanh, Sigmoid\n",
    "\n",
    "\n",
    "from functools import reduce\n",
    "import operator\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "class HadamardModule(rb.custom.CustomModule):\n",
    "    def get_out_shape(self, in_shapes):\n",
    "        return in_shapes[0]\n",
    "\n",
    "    def forward(self, inputs, _):\n",
    "        return prod(inputs), ()\n",
    "\n",
    "Hadamard = custom.register_recurrent(module_class=HadamardModule, flatten_input=False, single_step=False, unroll_full_state=False)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "hidden_size = 32\n",
    "n = rb.Network()\n",
    "\n",
    "n.output = rb.Placeholder()\n",
    "n.h_and_i = n.input.stack(n.output)\n",
    "\n",
    "n.i = n.h_and_i.apply(Linear(hidden_size), Sigmoid())\n",
    "n.f = n.h_and_i.apply(Linear(hidden_size), Sigmoid())\n",
    "n.o = n.h_and_i.apply(Linear(hidden_size), Sigmoid())\n",
    "n.g = n.h_and_i.apply(Linear(hidden_size), Tanh())\n",
    "\n",
    "n.c = rb.Placeholder()\n",
    "n.c_1 = n.f.append(n.c).apply(Hadamard())\n",
    "n.c_2 = n.i.append(n.g).apply(Hadamard())\n",
    "\n",
    "n.c = n.c_1.sum(n.c_2)\n",
    "n.tan_c = n.c.apply(Tanh())\n",
    "n.output = n.o.append(n.tan_c).apply(Hadamard())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "seq = 8\n",
    "batch = 32\n",
    "inp_shape = (100,)\n",
    "example = torch.rand((seq,batch)+inp_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "model = n.make_model(inp_shape)\n",
    "lstm = torch.nn.LSTM(inp_shape[0], hidden_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.inner.layers.c0.layers.i.mlist[0].inner.weight.data,\\\n",
    "    model.inner.layers.c0.layers.f.mlist[0].inner.weight.data,\\\n",
    "    model.inner.layers.c0.layers.g.mlist[0].inner.weight.data,\\\n",
    "    model.inner.layers.c0.layers.o.mlist[0].inner.weight.data = torch.cat((lstm.weight_hh_l0, lstm.weight_ih_l0), dim=-1).chunk(4)\n",
    "\n",
    "    model.inner.layers.c0.layers.i.mlist[0].inner.bias.data,\\\n",
    "    model.inner.layers.c0.layers.f.mlist[0].inner.bias.data,\\\n",
    "    model.inner.layers.c0.layers.g.mlist[0].inner.bias.data,\\\n",
    "    model.inner.layers.c0.layers.o.mlist[0].inner.bias.data = (lstm.bias_ih_l0 + lstm.bias_hh_l0).chunk(4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "out1, _ = model(example)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "out2, _ = lstm(example)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(False)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(out1, out2, atol=1e-7).all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "NestedNetworkModule(\n  (layers): ModuleDict(\n    (i): SequentialModule(\n      (mlist): ModuleList(\n        (0): StatelessWrapper(\n          (inner): Linear(in_features=132, out_features=32, bias=True)\n        )\n        (1): StatelessWrapper(\n          (inner): Sigmoid()\n        )\n      )\n    )\n    (f): SequentialModule(\n      (mlist): ModuleList(\n        (0): StatelessWrapper(\n          (inner): Linear(in_features=132, out_features=32, bias=True)\n        )\n        (1): StatelessWrapper(\n          (inner): Sigmoid()\n        )\n      )\n    )\n    (o): SequentialModule(\n      (mlist): ModuleList(\n        (0): StatelessWrapper(\n          (inner): Linear(in_features=132, out_features=32, bias=True)\n        )\n        (1): StatelessWrapper(\n          (inner): Sigmoid()\n        )\n      )\n    )\n    (g): SequentialModule(\n      (mlist): ModuleList(\n        (0): StatelessWrapper(\n          (inner): Linear(in_features=132, out_features=32, bias=True)\n        )\n        (1): StatelessWrapper(\n          (inner): Tanh()\n        )\n      )\n    )\n    (c_1): RecurrentWrapper(\n      (inner): HadamardModule()\n    )\n    (c_2): RecurrentWrapper(\n      (inner): HadamardModule()\n    )\n    (c): ModuleBase()\n    (tan_c): StatelessWrapper(\n      (inner): Tanh()\n    )\n    (output): RecurrentWrapper(\n      (inner): HadamardModule()\n    )\n  )\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inner.layers.c0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([128, 100])\n",
      "weight_hh_l0 torch.Size([128, 32])\n",
      "bias_ih_l0 torch.Size([128])\n",
      "bias_hh_l0 torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for name, p in lstm.named_parameters():\n",
    "    print(name, p.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner.layers.c0.layers.i.mlist.0.inner.weight torch.Size([32, 132])\n",
      "inner.layers.c0.layers.i.mlist.0.inner.bias torch.Size([32])\n",
      "inner.layers.c0.layers.f.mlist.0.inner.weight torch.Size([32, 132])\n",
      "inner.layers.c0.layers.f.mlist.0.inner.bias torch.Size([32])\n",
      "inner.layers.c0.layers.o.mlist.0.inner.weight torch.Size([32, 132])\n",
      "inner.layers.c0.layers.o.mlist.0.inner.bias torch.Size([32])\n",
      "inner.layers.c0.layers.g.mlist.0.inner.weight torch.Size([32, 132])\n",
      "inner.layers.c0.layers.g.mlist.0.inner.bias torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(name, p.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 132])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((lstm.weight_ih_l0, lstm.weight_hh_l0), dim=-1).chunk(4)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}