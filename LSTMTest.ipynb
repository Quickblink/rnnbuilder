{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append('library/src')\n",
    "import rnnbuilder as rb\n",
    "from rnnbuilder import custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from rnnbuilder.nn import ReLU, Conv2d, Linear, Tanh, Sigmoid\n",
    "\n",
    "\n",
    "from functools import reduce\n",
    "import operator\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "class HadamardModule(rb.custom.CustomModule):\n",
    "    def get_out_shape(self, in_shapes):\n",
    "        return in_shapes[0]\n",
    "\n",
    "    def forward(self, inputs, _):\n",
    "        return prod(inputs), ()\n",
    "\n",
    "Hadamard = custom.register_recurrent(module_class=HadamardModule, flatten_input=False, single_step=False, unroll_full_state=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hidden_size = 32\n",
    "n = rb.Network()\n",
    "\n",
    "n.i_i = n.input.apply(Linear(hidden_size))\n",
    "n.i_f = n.input.apply(Linear(hidden_size))\n",
    "n.i_o = n.input.apply(Linear(hidden_size))\n",
    "n.i_g = n.input.apply(Linear(hidden_size))\n",
    "\n",
    "n.output = rb.Placeholder()\n",
    "n.h_i = n.output.apply(Linear(hidden_size))\n",
    "n.h_f = n.output.apply(Linear(hidden_size))\n",
    "n.h_o = n.output.apply(Linear(hidden_size))\n",
    "n.h_g = n.output.apply(Linear(hidden_size))\n",
    "\n",
    "n.i = n.i_i.sum(n.h_i).apply(Sigmoid())\n",
    "n.f = n.i_f.sum(n.h_f).apply(Sigmoid())\n",
    "n.o = n.i_o.sum(n.h_o).apply(Sigmoid())\n",
    "n.g = n.i_g.sum(n.h_g).apply(Tanh())\n",
    "\n",
    "n.c = rb.Placeholder()\n",
    "n.c_1 = n.f.append(n.c).apply(Hadamard())\n",
    "n.c_2 = n.i.append(n.g).apply(Hadamard())\n",
    "\n",
    "n.c = n.c_1.sum(n.c_2)\n",
    "n.tan_c = n.c.apply(Tanh())\n",
    "n.output = n.o.append(n.tan_c).apply(Hadamard())\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "hidden_size = 32\n",
    "n = rb.Network()\n",
    "\n",
    "n.output = rb.Placeholder()\n",
    "n.h_and_i = n.input.stack(n.output)\n",
    "\n",
    "n.i = n.h_and_i.apply(Linear(hidden_size), Sigmoid())\n",
    "n.f = n.h_and_i.apply(Linear(hidden_size), Sigmoid())\n",
    "n.o = n.h_and_i.apply(Linear(hidden_size), Sigmoid())\n",
    "n.g = n.h_and_i.apply(Linear(hidden_size), Tanh())\n",
    "\n",
    "n.c = rb.Placeholder()\n",
    "n.c_1 = n.f.append(n.c).apply(Hadamard())\n",
    "n.c_2 = n.i.append(n.g).apply(Hadamard())\n",
    "\n",
    "n.c = n.c_1.sum(n.c_2)\n",
    "n.tan_c = n.c.apply(Tanh())\n",
    "n.output = n.o.append(n.tan_c).apply(Hadamard())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "seq = 8\n",
    "batch = 32\n",
    "inp_shape = (100,)\n",
    "example = torch.rand((seq,batch)+inp_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = n.make_model(inp_shape)\n",
    "lstm = torch.nn.LSTM(inp_shape[0], hidden_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.inner.layers.i_i.inner.weight.data,\\\n",
    "    model.inner.layers.i_f.inner.weight.data,\\\n",
    "    model.inner.layers.i_g.inner.weight.data,\\\n",
    "    model.inner.layers.i_o.inner.weight.data = lstm.weight_ih_l0.chunk(4, 0)\n",
    "\n",
    "    model.inner.layers.i_i.inner.bias.data,\\\n",
    "    model.inner.layers.i_f.inner.bias.data,\\\n",
    "    model.inner.layers.i_g.inner.bias.data,\\\n",
    "    model.inner.layers.i_o.inner.bias.data = lstm.bias_ih_l0.chunk(4)\n",
    "\n",
    "    model.inner.layers.c0.layers.h_i.inner.weight.data,\\\n",
    "    model.inner.layers.c0.layers.h_f.inner.weight.data,\\\n",
    "    model.inner.layers.c0.layers.h_g.inner.weight.data,\\\n",
    "    model.inner.layers.c0.layers.h_o.inner.weight.data = lstm.weight_hh_l0.chunk(4, 0)\n",
    "\n",
    "    model.inner.layers.c0.layers.h_i.inner.bias.data,\\\n",
    "    model.inner.layers.c0.layers.h_f.inner.bias.data,\\\n",
    "    model.inner.layers.c0.layers.h_g.inner.bias.data,\\\n",
    "    model.inner.layers.c0.layers.h_o.inner.bias.data = lstm.bias_hh_l0.chunk(4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "out1, _ = model(example)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "out2, _ = lstm(example)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(True)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(out1, out2, atol=1e-7).all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.0000e+00,  1.4901e-08,  1.4901e-08,  ...,  0.0000e+00,\n           0.0000e+00,  0.0000e+00],\n         [-1.4901e-08, -1.4901e-08,  0.0000e+00,  ...,  4.6566e-10,\n           0.0000e+00,  0.0000e+00],\n         [ 0.0000e+00, -1.4901e-08,  0.0000e+00,  ...,  0.0000e+00,\n           0.0000e+00,  0.0000e+00],\n         ...,\n         [ 7.4506e-09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n           0.0000e+00,  0.0000e+00],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n           0.0000e+00,  3.7253e-09],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n           0.0000e+00,  0.0000e+00]],\n\n        [[ 0.0000e+00,  0.0000e+00,  5.9605e-08,  ...,  3.7253e-09,\n           4.4703e-08,  3.7253e-09],\n         [ 7.4506e-09,  0.0000e+00,  4.4703e-08,  ...,  2.9802e-08,\n           3.7253e-09, -7.4506e-09],\n         [-3.7253e-09, -1.4901e-08, -1.4901e-08,  ...,  1.6298e-09,\n           2.2352e-08, -2.2352e-08],\n         ...,\n         [ 1.4901e-08,  0.0000e+00,  0.0000e+00,  ..., -2.9802e-08,\n           1.4901e-08,  1.1176e-08],\n         [-7.4506e-09,  0.0000e+00,  2.9802e-08,  ..., -3.7253e-08,\n           0.0000e+00,  2.9802e-08],\n         [-1.4901e-08,  0.0000e+00,  0.0000e+00,  ...,  1.4901e-08,\n           2.9802e-08,  0.0000e+00]],\n\n        [[-7.4506e-09, -2.9802e-08,  2.9802e-08,  ...,  1.8626e-08,\n           0.0000e+00,  0.0000e+00],\n         [-7.4506e-09,  0.0000e+00,  1.1921e-07,  ...,  3.9116e-08,\n          -8.3819e-09,  5.5879e-09],\n         [ 7.4506e-09, -5.9605e-08,  2.9802e-08,  ...,  4.4703e-08,\n           2.9802e-08, -2.2352e-08],\n         ...,\n         [ 2.9802e-08, -2.9802e-08,  0.0000e+00,  ..., -2.9802e-08,\n          -2.9802e-08,  1.4901e-08],\n         [ 1.4901e-08, -8.9407e-08, -1.6391e-07,  ...,  2.9802e-08,\n          -2.9802e-08,  1.4901e-08],\n         [-1.1176e-08,  0.0000e+00,  2.9802e-08,  ...,  0.0000e+00,\n          -2.9802e-08, -1.4901e-08]],\n\n        ...,\n\n        [[-7.4506e-09,  5.9605e-08, -2.9802e-08,  ...,  0.0000e+00,\n           5.9605e-08, -1.4901e-08],\n         [ 2.9802e-08,  0.0000e+00,  0.0000e+00,  ...,  4.4703e-08,\n           2.9802e-08,  0.0000e+00],\n         [-1.4901e-08,  0.0000e+00,  8.9407e-08,  ...,  0.0000e+00,\n           0.0000e+00, -2.2352e-08],\n         ...,\n         [ 3.7253e-09,  0.0000e+00, -1.4901e-08,  ..., -2.9802e-08,\n           1.4901e-08, -7.4506e-09],\n         [-1.4901e-08,  0.0000e+00,  2.9802e-08,  ...,  1.4901e-08,\n           0.0000e+00,  0.0000e+00],\n         [-3.7253e-09, -8.9407e-08,  0.0000e+00,  ...,  2.9802e-08,\n           0.0000e+00, -7.4506e-09]],\n\n        [[ 7.4506e-09,  5.9605e-08, -1.1921e-07,  ..., -2.9802e-08,\n           2.9802e-08, -3.7253e-09],\n         [-7.4506e-09,  2.9802e-08,  2.9802e-08,  ...,  2.9802e-08,\n          -2.9802e-08,  0.0000e+00],\n         [-2.9802e-08,  0.0000e+00,  8.9407e-08,  ...,  2.9802e-08,\n           0.0000e+00,  0.0000e+00],\n         ...,\n         [-3.7253e-08, -2.9802e-08, -2.9802e-08,  ..., -2.9802e-08,\n           0.0000e+00,  2.9802e-08],\n         [ 1.8626e-09,  0.0000e+00,  2.9802e-08,  ..., -1.4901e-08,\n          -5.9605e-08,  0.0000e+00],\n         [-1.1176e-08, -5.9605e-08,  0.0000e+00,  ...,  2.9802e-08,\n          -2.9802e-08,  0.0000e+00]],\n\n        [[-1.4901e-08,  0.0000e+00,  8.9407e-08,  ...,  0.0000e+00,\n           0.0000e+00, -9.3132e-10],\n         [ 0.0000e+00,  0.0000e+00,  2.9802e-08,  ...,  0.0000e+00,\n           0.0000e+00,  7.4506e-09],\n         [ 1.4901e-08,  0.0000e+00,  0.0000e+00,  ...,  5.9605e-08,\n           0.0000e+00, -1.4901e-08],\n         ...,\n         [-1.4901e-08,  0.0000e+00, -7.4506e-08,  ..., -2.9802e-08,\n           0.0000e+00,  0.0000e+00],\n         [-7.4506e-09,  0.0000e+00,  0.0000e+00,  ..., -1.4901e-08,\n          -7.4506e-08, -1.4901e-08],\n         [-9.3132e-09,  2.9802e-08, -2.9802e-08,  ...,  4.4703e-08,\n          -5.9605e-08, -1.4901e-08]]], grad_fn=<SubBackward0>)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1-out2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([128, 100])\n",
      "weight_hh_l0 torch.Size([128, 32])\n",
      "bias_ih_l0 torch.Size([128])\n",
      "bias_hh_l0 torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for name, p in lstm.named_parameters():\n",
    "    print(name, p.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner.layers.c0.layers.i.mlist.0.inner.weight torch.Size([32, 132])\n",
      "inner.layers.c0.layers.i.mlist.0.inner.bias torch.Size([32])\n",
      "inner.layers.c0.layers.f.mlist.0.inner.weight torch.Size([32, 132])\n",
      "inner.layers.c0.layers.f.mlist.0.inner.bias torch.Size([32])\n",
      "inner.layers.c0.layers.o.mlist.0.inner.weight torch.Size([32, 132])\n",
      "inner.layers.c0.layers.o.mlist.0.inner.bias torch.Size([32])\n",
      "inner.layers.c0.layers.g.mlist.0.inner.weight torch.Size([32, 132])\n",
      "inner.layers.c0.layers.g.mlist.0.inner.bias torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(name, p.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 132])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((lstm.weight_ih_l0, lstm.weight_hh_l0), dim=-1).chunk(4)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    model.inner.layers.c0.layers.i.mlist[0].inner.weight.data,\\\n",
    "    model.inner.layers.c0.layers.f.mlist[0].inner.weight.data,\\\n",
    "    model.inner.layers.c0.layers.g.mlist[0].inner.weight.data,\\\n",
    "    model.inner.layers.c0.layers.o.mlist[0].inner.weight.data = torch.cat((lstm.weight_hh_l0, lstm.weight_ih_l0), dim=-1).chunk(4)\n",
    "\n",
    "    model.inner.layers.c0.layers.i.mlist[0].inner.bias.data,\\\n",
    "    model.inner.layers.c0.layers.f.mlist[0].inner.bias.data,\\\n",
    "    model.inner.layers.c0.layers.g.mlist[0].inner.bias.data,\\\n",
    "    model.inner.layers.c0.layers.o.mlist[0].inner.bias.data = (lstm.bias_ih_l0 + lstm.bias_hh_l0).chunk(4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}